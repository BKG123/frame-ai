# ğŸ“· **Frame AI â€“ Photography Coach**

**Frame AI** is an AI-powered photography analysis and coaching tool that provides professional, real-time feedback on your photos. Designed with photographersâ€”amateurs and pros alikeâ€”in mind, it delivers actionable insights through a sleek, modern web interface.

ğŸŒ **Live Demo:** [https://frame-ai.bejayketanguin.com](https://frame-ai.bejayketanguin.com)

---

## âœ¨ Features

* ğŸ“¸ **AI-Powered Photo Critique** â€“ Get expert feedback on composition, lighting, and framing powered by [Gemini ](https://aistudio.google.com/welcome).
* ğŸ¨ **AI Image Enhancement** â€“ Generate improved versions of your photos based on the analysis feedback.
* ğŸ”„ **Real-Time Streaming Analysis** â€“ Watch the AI's thought process unfold as it analyzes your photo.
* ğŸ“· **EXIF Data Insights** â€“ Understand how your camera settings impact the shot.
* ğŸ“‹ **Structured Feedback** â€“ Organized sections for strengths, improvements, and tips with expandable analysis cards.
* ğŸŒ **Responsive Interface** â€“ Works on desktop and mobile with drag-and-drop uploads.
* ğŸŒ™ **Dark/Light Mode** â€“ Automatically adapts to your system preferences or manually toggle.
* ğŸ“‹ **Shareable Results** â€“ Copy and share feedback with ease.
* ğŸš€ **FastAPI Backend** â€“ Built for speed with streaming support and auto-generated API docs.
* ğŸ“Š **LLM Observability** â€“ Optional Langfuse integration for tracking LLM calls, costs, and performance.

---

## ğŸš€ Quick Start

### âœ… Prerequisites

* **Docker & Docker Compose** (recommended) OR
* **Python 3.11 or later** (for local development)
* An [Gemini API key](https://aistudio.google.com/welcome) for AI analysis

---

### ğŸ“‚ Installation

1. **Clone the repository:**

   ```bash
   git clone https://github.com/BKG123/frame-ai.git
   cd frame-ai
   ```

2. **Install dependencies with uv:**

   ```bash
   uv sync
   ```

   > If you donâ€™t have `uv`, install it:

   ```bash
   curl -LsSf https://astral.sh/uv/install.sh | sh
   ```

3. **Configure environment variables:**

   ```bash
   cp .env.example .env
   # Edit .env and add your GEMINI_API_KEY
   ```

   **Optional: Enable Langfuse for LLM observability**

   See [LANGFUSE_SETUP.md](LANGFUSE_SETUP.md) for detailed instructions on setting up LLM tracking.

---

### â–¶ Running the Application

#### ğŸ³ Using Docker (Recommended)

The easiest way to run Frame AI is using Docker:

```bash
# Build and start the container
docker-compose up -d

# View logs
docker-compose logs -f

# Stop the container
docker-compose down
```

Or build manually:

```bash
# Build the image
docker build -t frame-ai .

# Run the container
docker run -p 8000:8000 --env-file .env frame-ai
```

#### ğŸ’» Using Python directly

Start the server with hot reloading:

```bash
uv run uvicorn main:app --reload
```

Or run it directly:

```bash
uv run python main.py
```

Access it at:

* **Web Interface:** `http://localhost:8000`
* **API Docs:** `http://localhost:8000/docs`
* **Health Check:** `http://localhost:8000/health`

---

## ğŸ“¦ API Endpoints

### ğŸ“¸ Photo Analysis

* `POST /upload` â€“ Upload your photo and receive real-time analysis.

### ğŸ¨ Image Enhancement

* `POST /image/edit` â€“ Generate an enhanced version of your photo based on analysis feedback.
* `POST /image/generate` â€“ Create or edit images using custom prompts with AI.

### âœ… Utility

* `GET /health` â€“ Check if the service is running.
* `GET /` â€“ Access the web interface.

---

## ğŸ›  Development

### Code Quality

Maintain standards using:

```bash
# Lint with ruff
uv run ruff check .

# Type check with mypy
uv run mypy .

# Install pre-commit hooks
uv run pre-commit install
```

### ğŸ“‚ Project Structure

```
frame-ai/
â”œâ”€â”€ config/                  # Configuration files and logging
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â””â”€â”€ langfuse_config.py  # Langfuse observability config
â”œâ”€â”€ services/                # Core logic
â”‚   â”œâ”€â”€ analysis.py          # Photo critique and streaming
â”‚   â”œâ”€â”€ llm.py               # AI integration (with Langfuse tracing)
â”‚   â””â”€â”€ tools.py             # Image processing utilities
â”œâ”€â”€ api/                     # API routes and models
â”‚   â”œâ”€â”€ routes.py            # FastAPI route handlers (with Langfuse)
â”‚   â””â”€â”€ models.py            # Pydantic schemas
â”œâ”€â”€ static/
â”‚   â””â”€â”€ index.html          # Responsive web UI
â”œâ”€â”€ main.py                 # FastAPI app definition
â”œâ”€â”€ prompts.py              # AI prompt templates
â”œâ”€â”€ pyproject.toml          # Project dependencies with uv
â”œâ”€â”€ LANGFUSE_SETUP.md       # Langfuse integration guide
â””â”€â”€ LANGFUSE_INTEGRATION_SUMMARY.md  # Integration details
```

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a new branch:

   ```bash
   git checkout -b feature/amazing-feature
   ```
3. Implement your changes
4. Run tests:

   ```bash
   uv run ruff check . && uv run mypy .
   ```
5. Commit and push:

   ```bash
   git commit -m "Add amazing feature"
   git push origin feature/amazing-feature
   ```
6. Open a Pull Request!

---

## ğŸ“„ License

This project is open source. See the `LICENSE` file for details.

---

## ğŸ™ Acknowledgments

* Built with [FastAPI](https://fastapi.tiangolo.com/)
* AI analysis powered by [Gemini](https://gemini.google.com/app)
* Image processing using [Pillow](https://python-pillow.org/)
* LLM observability with [Langfuse](https://langfuse.com/)
